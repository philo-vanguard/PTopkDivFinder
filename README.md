# Fast Diversified Top-k Rule Discovery
Rule discovery is a fundamental task in data analysis, with broad applications in data cleaning, knowledge extraction, and decision making. However, existing methods often generate a large number of functionally redundant rules, with a high time cost. To address this, a recent line of work, the first to introduce diversified top-k rule discovery, aims to identify a set of top-ranked rules that are both relevant and diverse. Despite this advancement, it still suffers from high user interaction overhead, computational inefficiency, and the inability to handle a common scenario of selecting a diverse subset from an existing rule set.

In this paper, we propose a user-friendly and efficient framework for diversified top-k rule discovery. As a testbed, we consider Entity Enhancing Rules (REEs), which subsume common association rules and data quality rules as special cases. Our method allows users to specify lightweight preference templates, which are used to train a correlation model that captures user preferences and generates subjective embeddings for predicates and rules. Based on these embeddings, we define an objective function to jointly measure the relevance and diversity of rules in a unified vector space; moreover, we formulate and study two key problems: (i) selecting diversified top-k rules from an existing redundant rule set, and (ii) discovering diversified top-k rules directly from raw data. We prove that both problems are intractable and propose effective algorithms; in particular, the second problem is more challenging and thus we further optimize its solution with carefully designed pruning strategies and parallel optimization. Extensive evaluation on real-world datasets demonstrates that our algorithms consistently identify top-ranked relevant and diverse rules, achieving an average 14.4X speedup (up to 35.57X) over the state-of-the-art method.

<br>

The codes consist of three main parts:
1. (Step 1) *Correlation Model*: codes for learning the correlation model M_corr, which learns user preferences and generates subjective embeddings of predicates and rules;  
2. (Step 2) *Optimization Preparations*: train the validity model and obtain frequent constant predicate combinations offline;
3. (Step 3) *Rule Discovery*: codes for discovering top-k relevant and diversified rules, based on the user-guided embedding-based objective function;

The correlation model trained in step 1, along with validity model and frequent constant predicate combination learned in step2, play crucial roles in the subsequent rule discovery phase (step 3). It enables the system to effectively identify and discover valuable rules.

## Installation
Before building the projects, the following prerequisites need to be installed:
* Java JDK 1.8
* Maven
* Transformers
* Tensorflow 2.6.2
* Pytorch 1.10.2
* Huggingface distilbert-base-uncased

## Datasets and Models
All datasets and well-trained correlation models used in this paper have been uploaded in Google Drive[https://drive.google.com/drive/folders/1HsdCay67xmcBP1vQ0wRpKohwInMsgzpA].
You can download them, skip step 1 and step 2, and run step 3 directly.

Below, we show the process of learning correlation model (step 1), train validity model and obtain frequent constant predicate combinations (step 2), and running rule discovery (step 3),
using 'airports' dataset as an example.

## Step 1: Correlation Model
The *relevance_model* folder contains the datasets and source code for learning the correlation model M_corr.

### 1. Rules and data used for training correlation model
```
ls ./datasets/airports/
airports.csv  airports_sample.csv  all_predicates.txt  rules.txt  airports_embedding_filtered.csv  train/

ls ./datasets/airports/train/
train.csv test.csv
```

(1) The file 'airports.csv' contains the raw data, while 'airports_sample.csv' is a sample of 'airports.csv', referred to as D_s in the paper. 

(2) The file 'all_predicates.txt' contains all predicates, generated by running `./relevance_model/preprocess/enumerate_all_predicates.py`.

(3) The file 'rules.txt' is a set of rules used in the paper for correltaion model training,
discovered from D_s, i.e., airports_sample.csv, using existing rule discovery method [PRMiner](https://github.com/philo-vanguard/PRMiner).

(4) The file 'airports_embedding_filtered.csv' contains the learned embeddings for each attribute and value from 'airports_sample.csv'. 
These embeddings were generated using [EmbDI](https://gitlab.eurecom.fr/cappuzzo/embdi.git) and subsequently fillered through `./relevance_model/preprocess/filterEmbedding.py`.

(5) The folder 'train/' contains the training and testing data for correlation model, generated by
`./relevance_model/preprocess/construct_labelled_rule_pairs.py`.
The results will be saved in '../../datasets/airports/train/', used for the training of correlation model.


### 2. Train the correlation model M_corr
```
cd ./relevance_model/
./run_correlation_model.sh
```
The results will be saved in './datasets/airports/train/model/model.txt'

## Step 2: Optimization Preparations
### 1. Train the validity model M_valid
```
cd ./relevance_model/
python validityModel.py
```
The results will be saved in './datasets/airports/train_validity/xgboost_model.bin'.
<!-- The results will be saved in './datasets/airports/train_validity/xgboost_model_supp${supp_thr}_conf${conf_thr}.bin'.
Here, \${supp\_thr} and \${conf\_thr} are the configured thresholds of support and confidence, respectively. -->


### 2. Obtain frequent constant predicates offline
```
cd ./relevance_model/
python frequentConstantCombinationLearning.py
```
The results will be saved in './datasets/airports/frequentConstantCombinations_${thr}.txt'
Here, \${thr} is the configured support threshold.



## Step 3: Rule Discovery
The *mls-server* folder contains the source code for top-k relevant and diversified REE discovery.
Below we give a toy example.

### 1. Put the datasets into HDFS:
```
hdfs dfs -mkdir /tmp/diversified_data/
hdfs dfs -put airports.csv /tmp/diversified_data/
```

### 2. Put the saved correlation model along with related files, from ./datasets/, into HDFS:
```
hdfs dfs mkdir -p /tmp/rulefind/files_diversified/airports/
hdfs dfs -put ./datasets/airports/all_predicates.txt /tmp/rulefind/files_diversified/airports/
hdfs dfs -put ./datasets/airports/train/model/model.txt /tmp/rulefind/files_diversified/airports/
hdfs dfs -put ./datasets/airports/train/model/frequentConstantCombinations.txt /tmp/rulefind/files_diversified/airports/
hdfs dfs -put ./datasets/airports/train/model/rulesUserAlreadyKnown.txt /tmp/rulefind/files_diversified/airports/
hdfs dfs -put ./datasets/airports/train/model/xgboost_model.bin /tmp/rulefind/files_diversified/airports/
```



### 3. Download all the dependencies (https://drive.google.com/drive/folders/1Gviqt7zcaRGQho4x5i6hPnuwPmWonWFR?usp=sharing), then move the directory lib/ into mls-server/example/:
```
cd mls-server/
mv lib/ example/
```

### 4. Compile and build the project:
```
mvn package
```
Then move and replace the **mls-server-0.1.1.jar** from mls-server/target/ to example/lib/:
```
mv target/mls_server-0.1.1.jar example/lib/
```

### 5. After all these preparation, run the toy example:
```
cd example/scripts/
./example.sh
```
The results, i.e., discovered rules will be shown in discoveryResultsTopKDiversified/, as 'resRootDir' in run_unit.sh shows.


<font color=red> 
Notice that, if you want to reproduce all the experiments in the paper, you may run the 'reproduce_all_experiments.sh' file, as follows.
</font>

```
cd example/scripts/
./reproduce_all_experiments.sh
```

### 6. Explanations for the parameters in scripts
* dataID: the ID of dataset;
* expOption: the description of discovery task;
* suppDefault: the threshold for support;
* confDefault: the threshold for confidence;
* topKDefault: the k size in discovery;
* tupleNumDefault: the number of tuple variables;
* numOfProcessorDefault: the number of processors;
* relevanceDefualt: the relevance metrics used in discovery;
* diversityDefualt: the diversity metrics used in discovery;
* lambda: the weight of diversity score;
* w_fitness: the weight of fitness metric when computing score;
* w_unexpectedness: the weight of unexpectedness metric when computing score;
* max_X_len_default: the max length of X of rules;
* attributesUserInterested: the set of user-interested attributes;
* rulesUserAlreadyKnownFile: the set of user-accumulated rules;
* validityModelFile: the validity model;
* predictConfThreshold: the confidence threshold of the prediction of validity model;
* ifCheckValidityByMvalid: whether use validity model;
* ifConstantOffline: whether separately process constant predicates during discovery;


## Release License
Please see the **LICENSE.txt** file.

